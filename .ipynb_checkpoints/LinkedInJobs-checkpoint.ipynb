{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8855f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver.v2 as uc\n",
    "from selenium.webdriver.common.by import By                                  ### Module\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "import pandas as pd\n",
    "import itertools \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1660ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = uc.Chrome()  # loading undetectable chrome browser\n",
    "\n",
    "driver.get('https://www.careerguide.com/career-options')  ## scraping careerguide website to get career names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a0a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "Catogery = []\n",
    "State = []\n",
    "Job_links = []\n",
    "company_links = []\n",
    "Company_Name = []\n",
    "Job_location = []\n",
    "Job _Title= []\n",
    "\n",
    "df_bike_ = pd.DataFrame(columns=['Catogery','State','Job links', 'company links','Job loction','Job Title','Company Name'])   # defining columns for excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25879ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "careerTitle = []  # list to store career title\n",
    "careerTitleOpt= driver.find_elements(By.XPATH,\"//*[@class='col-md-4']/ul/li\")  ## scraping careerTitle from careerguide website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8e6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in careerTitleOpt[1:2]:  ## only scraping for 10 job title\n",
    "    careerTitle.append(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c454f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.linkedin.com/')  ## getting linkedin website to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f31de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = driver.find_element(By.ID,\"session_key\")               ## signing with username and password on linkedin\n",
    "username.send_keys(\"chaudhary.s.shamshad07@gmail.com\")           ## sending input text to input area\n",
    "password = driver.find_element(By.ID,\"session_password\")\n",
    "password.send_keys(\"Shamshad\")                                   ##****your_password*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a7b44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find Button\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    login_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME,\"sign-in-form__submit-button\"))   ## locator login button for linkedin\n",
    "    )\n",
    "    login_button.click()   # clicking login button\n",
    "finally:\n",
    "    print(\"cannot find Button\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c86e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_button=driver.find_element(By.XPATH,\"(//*[@class='app-aware-link  global-nav__primary-link'])[2]\") ## locator for job section\n",
    "job_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6d29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Locations = ['punjab','Delhi','Mumbai']  ## for now only scraping for three location\n",
    "infos=[]\n",
    "comp_links=[] ## list to store company links to scrape their info later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2f9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Location in Locations:  ## double looping for each location with job careertitle\n",
    "    for Title in careerTitle:\n",
    "        url = \"https://www.linkedin.com/jobs/search/?currentJobId=3348462787&geoId=106187582&keywords=\"+Title+\"&location=\"+Location+\"%2C%20India&refresh=true\"\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        flag=1\n",
    "        page_no = 25\n",
    "        current_url = driver.current_url\n",
    "            \n",
    "        while(flag>0):\n",
    "            ## locator for job info which as location, mode, title, company name separeted by newline\n",
    "            info_div=driver.find_elements(By.XPATH,\"//*[@class='flex-grow-1 artdeco-entity-lockup__content ember-view']\")\n",
    "\n",
    "            ## locator for job links and company links\n",
    "            job_Links = driver.find_elements(By.XPATH,\"(//*[@class='flex-grow-1 artdeco-entity-lockup__content ember-view']/div[1]/a)\")\n",
    "            comp_Links = driver.find_elements(By.XPATH,\"(//*[@class='flex-grow-1 artdeco-entity-lockup__content ember-view']/div[2]/a)\")\n",
    "\n",
    "            # try for if there is any job with given title\n",
    "            try:\n",
    "                checkProduct=driver.find_element(By.XPATH,\"//*[@class='t-24 t-black t-normal text-align-center']\").text\n",
    "            except:\n",
    "                checkProduct=''\n",
    "\n",
    "            ## if no job with given title found pass to next job title\n",
    "            if(checkProduct==\"No matching jobs found.\"):\n",
    "                flag=0\n",
    "            else:\n",
    "                                                                                 # Specifying default value as ''\n",
    "                for (i,job_link,comp_link) in itertools.zip_longest(info_div,job_Links,comp_Links, fillvalue=''):\n",
    "                    data = []\n",
    "                    try:\n",
    "                        infos.append(i.text)   ## appending job info which contains (location,mode,job title,company name) separated by newline\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                         ## appending carrer title\n",
    "                        Catogery.append(Title) \n",
    "                    except:\n",
    "                        Catogery.append('')\n",
    "\n",
    "                    try:\n",
    "                        ## appendig state location\n",
    "                        State.append(Location)\n",
    "                    except:\n",
    "                        State.append(Location)\n",
    "\n",
    "                    try:\n",
    "                        ## appending job links\n",
    "                        Job_links.append(job_link.get_attribute('href'))\n",
    "                    except:\n",
    "                        Job_links.append('')\n",
    "\n",
    "                    try:\n",
    "                        comp_links.append(comp_link.get_attribute('href'))   ## appending company links in separate list to scrape their data later on\n",
    "                        ## appending company links\n",
    "                        company_links.append(comp_link.get_attribute('href'))\n",
    "                    except:\n",
    "                        company_links.append('')\n",
    "\n",
    "\n",
    "                next_page_url = current_url + \"&start=\" + str(page_no)\n",
    "                page_no=page_no+25\n",
    "                \n",
    "                try:\n",
    "                    checkNextPageButton=driver.find_element(By.XPATH,\"//*[@class='jobs-search-results-list__pagination pv5 artdeco-pagination ember-view']\").text\n",
    "                    if(checkNextPageButton):\n",
    "                        driver.get(next_page_url) \n",
    "                except:\n",
    "                    checkNextPageButton=''\n",
    "                    flag=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd41fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making location, mode , job title, company name from info above scraped due to they are separated by newline only in same locator\n",
    "def make(info):\n",
    "    lst = []\n",
    "    string = \"\"\n",
    "    for i in info:\n",
    "        if i!=\"\\n\":\n",
    "            string+=i\n",
    "        if i==\"\\n\": \n",
    "            lst.append(string)\n",
    "            string=\"\"\n",
    "            \n",
    "    lst.append(string)   \n",
    "    return lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cef102d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Job_location' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m## appending job location \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mJob_location\u001b[49m\u001b[38;5;241m.\u001b[39mappend(lst[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_location' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     Job_location\u001b[38;5;241m.\u001b[39mappend(lst[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mJob_location\u001b[49m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m## appending job title\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     Job_Title\u001b[38;5;241m.\u001b[39mappend(lst[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Job_location' is not defined"
     ]
    }
   ],
   "source": [
    "for info in infos:\n",
    "    data=[]\n",
    "    lst = make(info)\n",
    "    try:\n",
    "        ## appending job location \n",
    "        Job_location.append(lst[0])\n",
    "    except:\n",
    "        Job_location.append('')\n",
    "        \n",
    "    try:\n",
    "        ## appending job title\n",
    "        Job_Title.append(lst[1])\n",
    "    except:\n",
    "        Job_Title.append('')\n",
    "    \n",
    "    try:\n",
    "        ## appending company name\n",
    "        Company_Name.append(lst[2])\n",
    "    except:\n",
    "        Company_Name.append()\n",
    "        \n",
    "    try:\n",
    "        ## appending mode of work\n",
    "        Mode.append(lst[3])\n",
    "    except:\n",
    "        Mode.append('')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoemployee(employeesNo):\n",
    "    for div in employeesNo:\n",
    "        div = div.text\n",
    "        last=div.partition(' ')[-1]\n",
    "        if last=='employees':\n",
    "            return div\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_links = set(comp_links)   ## getting set of company links so not to repeat same company in scraping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b542f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in comp_links:  ## getting link by link company info from comp_links list made during above process\n",
    "    data=[]\n",
    "    url = comp + 'about/'  ## definning url with about section of company\n",
    "        \n",
    "    driver.get(url)\n",
    "    \n",
    "    ## company name locator\n",
    "    try:\n",
    "        company_name=driver.find_element(By.XPATH,\"//*[@class='block mt2']\") \n",
    "    except:\n",
    "        company_name=''\n",
    "        \n",
    "    ## locator for company description\n",
    "    try:\n",
    "        description=driver.find_element(By.XPATH,\"//*[@class='break-words white-space-pre-wrap mb5 text-body-small t-black--light']\")\n",
    "    except:\n",
    "        description=''\n",
    "    \n",
    "    ## locator for numbers of employees \n",
    "    try:\n",
    "        employeesNo=driver.find_elements(By.XPATH,\"//*[@class='ember-view']/section/dl/dd\")\n",
    "    except:\n",
    "        employeesNo=''\n",
    "    \n",
    "    ## finding proper numbers of empoyeesv work data\n",
    "    try:\n",
    "        employees = getNoemployee(employeesNo)\n",
    "    except:\n",
    "        employees=''\n",
    "    \n",
    "    ## locator for location of company\n",
    "    try:\n",
    "        try:\n",
    "            location=driver.find_element(By.XPATH,\"//*[@class='ember-view artdeco-card p0 mb4']//li//p\")\n",
    "        except:\n",
    "            location=driver.find_element(By.XPATH,\"//*[@class='ember-view artdeco-card p0 mb4']//p\")\n",
    "    except:\n",
    "        location=''\n",
    "    \n",
    "    ## appending company name, description, number of employees, location\n",
    "    try:\n",
    "        data.append(company_name.text)\n",
    "    except:\n",
    "        data.append('')\n",
    "    try:\n",
    "        data.append(description.text)\n",
    "    except:\n",
    "        data.append('')\n",
    "    try:\n",
    "        data.append(employees)\n",
    "    except:\n",
    "        data.append('')\n",
    "    try:\n",
    "        data.append(location.text)\n",
    "    except:\n",
    "        data.append('')\n",
    "    \n",
    "    page.append(data)\n",
    "    wb.save(filename=workbook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Job_Title)):\n",
    "    df_bike_ = df_bike_.append({'Catogery':Catogery[i],'State':State[i],'Job links':Job_links[i], 'company links':company_links[i],\n",
    "                              'Job loction':Job_location[i],'Job Title':Job_Title[i],\n",
    "                              'Company Name':Company_Name[i], 'Mode':Mode[i]}, ignore_index=True)\n",
    "\n",
    "df_bike_.to_excel('job.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f529ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()  ## closing driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e858b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Job_Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7edc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
