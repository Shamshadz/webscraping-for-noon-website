{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd607498",
   "metadata": {},
   "source": [
    "### Import and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4614d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1bc9a",
   "metadata": {},
   "source": [
    "### This code was made to continue from remaning page, if program crash due some error(in my case internet)\n",
    "### we can input starting page no. and input upto which page no. you want to retrive data (50 products per page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e94d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_no = int(input(\"Enter page to start or continue scraping from : \"))\n",
    "print(\"for only 1 page scraping enter same input as above\")\n",
    "upto = int(input(\"upto which page number: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d3d73",
   "metadata": {},
   "source": [
    "### Chrome Driver setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "chrome_options = Options()\n",
    "prefs = {'profile.default_content_setting_values': {'images': 2}}   ## code for, no image to load \n",
    "\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9785e0",
   "metadata": {},
   "source": [
    "### checking above input page no.s and getting url load for mentioned page no.s\n",
    "### Also making excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bad134",
   "metadata": {},
   "outputs": [],
   "source": [
    "if page_no <= upto:\n",
    "    if page_no == 1:\n",
    "        ## Data headers for excel columns\n",
    "        df_bike = pd.DataFrame(columns=['Date','EAN/SKU','Position','Product Name','Currency','Product Price','Old Price','Product Rating','Product Rating Count',\n",
    "                                        'Brand','Store Name','Store Rating','Store Rating count','FBN','link'])\n",
    "        \n",
    "        ## according to above dataframe making excel file\n",
    "        df_bike.to_excel(f'Extraction.xlsx',index=False)\n",
    "\n",
    "        page_url = \"https://www.noon.com/egypt-en/sports-and-outdoors/exercise-and-fitness/yoga-16328/\"\n",
    "        driver.get(page_url) ## opening given url in chrome driver\n",
    "    else:\n",
    "        page_url = \"https://www.noon.com/egypt-en/sports-and-outdoors/exercise-and-fitness/yoga-16328/?limit=50&page=\"+str(page_no)+\"&sort%5Bby%5D=popularity&sort%5Bdir%5D=desc\"\n",
    "        driver.get(page_url)\n",
    "else:\n",
    "    print(\"second 2 should be greater than 1 input rerun program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()      ### opening window in full screen mode of chrome driver\n",
    "\n",
    "workbook_name = 'Extraction.xlsx'     ### getting excel file\n",
    "wb = load_workbook(workbook_name)      ### opening/loading excel excel file\n",
    "page = wb.active                       ### running excel file to append retrive data in it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = page_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5466b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(page_no,upto+1):   ## scarping pages at time According to mentioned page no. to upto page no.\n",
    "    \n",
    "    links = []\n",
    "    EANs = []\n",
    "\n",
    "    print(\"Scraping page \",i)\n",
    "    products = driver.find_elements(By.XPATH,\"(//div[@class='sc-cb3f65f3-7 pEiif grid']/span/a)\")  ### locator for list products on single page\n",
    "\n",
    "    for link in products:\n",
    "        try:\n",
    "            load_href = link.get_attribute('href')   ## getting href link of single product by looping products list of product\n",
    "        except:\n",
    "            load_herf = \"\"\n",
    "            \n",
    "        try:\n",
    "            load_EAN = link.get_attribute('id')   ## getting 'id' for retriving product serial numbers\n",
    "        except:\n",
    "            load_EAN = \"\"      \n",
    "        \n",
    "        links.append(load_href)\n",
    "\n",
    "        EAN = load_EAN.split('-')   ## making proper serial number from retrived id\n",
    "        EANs.append(EAN[1])\n",
    "    \n",
    "    count = 0\n",
    "    for link in links:         ### loop for product in products list\n",
    "        time.sleep(0.5)\n",
    "        driver.get(link)       ## opening single product page by using its link\n",
    "\n",
    "        data = []\n",
    "        \n",
    "        # Locators\n",
    "\n",
    "        today = date.today()    ## for date\n",
    "\n",
    "        try:\n",
    "            position = driver.find_element(By.XPATH,\"//div[@class='sc-e4a456cc-5 hsjerl']\").text  ## locator for position of product\n",
    "        except:\n",
    "            position = \"\"\n",
    "\n",
    "        try:\n",
    "            name = driver.find_element(By.XPATH,\"//h1[@class='sc-c44e3e2d-12 kODUYj']\").text  ## locator for name of product\n",
    "        except:\n",
    "            name = \"\"\n",
    "\n",
    "        try:\n",
    "            newPrice = driver.find_element(By.XPATH,\"//div[@class='priceNow']\").text  ## locator for sales price\n",
    "        except:\n",
    "            newPrice = 0\n",
    "\n",
    "        try:\n",
    "            oldPrice = driver.find_element(By.XPATH,\"//div[@class='priceWas']\").text    ## locator for original price\n",
    "        except:\n",
    "            oldPrice = \"\"\n",
    "\n",
    "        try:\n",
    "            proRating = driver.find_element(By.XPATH,\"//span[@class='sc-31ebbe94-1 bngoaw']\").text   ## locator for product Rating\n",
    "        except: \n",
    "            proRating = \"\"\n",
    "    \n",
    "        try:\n",
    "            proRatingCount = driver.find_element(By.XPATH,\"//div[@class='sc-53a159dc-0 iqpeOg']/span\").text   ## locator for product rating count\n",
    "        except:\n",
    "            proRatingCount = \"\"\n",
    "\n",
    "        try:\n",
    "            brand = driver.find_element(By.XPATH,\"//div[@class='sc-c44e3e2d-11 jbKJDi']\").text   ## locator for product brand\n",
    "        except:\n",
    "            brand = \"\"\n",
    "\n",
    "        try:\n",
    "            storeName = driver.find_element(By.XPATH,\"//span[@class='allOffers']\").text  ## locator for seller store Name\n",
    "        except:\n",
    "            storeName = \"\"\n",
    "\n",
    "        try:\n",
    "            fbn = driver.find_element(By.XPATH,\"//img[@class='sc-b51db3f-1 bGljQY']\").get_attribute('alt')  ## locator for FBN\n",
    "            fbn = fbn.split('-')\n",
    "            fbn = fbn[1]\n",
    "        except:\n",
    "            fbn = 0\n",
    "\n",
    "        try:\n",
    "            storeLink = WebDriverWait(driver, 1).until(\n",
    "                    EC.presence_of_element_located((By.XPATH,\"//button[@class='sc-d711b2ac-6 fssgSV']\"))  ## locator for store/seller link\n",
    "            )\n",
    "            time.sleep(1)\n",
    "            storeLink.click()   ## opening seller link page\n",
    "        except:\n",
    "            print(f'storeLink not found of {i} page product link: {link}')\n",
    "    \n",
    "        try:\n",
    "            storeRating = WebDriverWait(driver, 1).until(\n",
    "                    EC.presence_of_element_located((By.XPATH,\"//div[@class='sc-33d82e78-1 ekJjKz']\"))    ## locator for store Rating\n",
    "            )\n",
    "            storeRating = storeRating.text\n",
    "        except:\n",
    "            storeRating = \"\"\n",
    "    \n",
    "        try:\n",
    "            storeRatingCount = WebDriverWait(driver, 1).until(\n",
    "                    EC.presence_of_element_located((By.XPATH,\"(//div[@class='sc-33d82e78-0 hbyggc']/div)[3]\"))   ## locator for store Rating count\n",
    "            )\n",
    "            storeRatingCount = storeRatingCount.text\n",
    "        except:\n",
    "            storeRatingCount = \"\"\n",
    "            \n",
    "        ## arranging position of product properly\n",
    "        position = position.split('\\n')\n",
    "        position = position[0:4]\n",
    "        position = \"/\".join(position)\n",
    "            \n",
    "        ## making list to append data in excel (should be proper format according to headers)\n",
    "        data.append(today)\n",
    "        data.append(EANs[count])\n",
    "        data.append(position)\n",
    "        data.append(name)\n",
    "        data.append(newPrice.split()[0] if newPrice else newPrice)\n",
    "        data.append(newPrice.split()[1] if newPrice else newPrice)\n",
    "        data.append(oldPrice.split()[1] if oldPrice else oldPrice)\n",
    "        data.append(proRating)\n",
    "        data.append(proRatingCount.split()[0] if proRatingCount else proRatingCount)\n",
    "        data.append(brand)\n",
    "        data.append(storeName)\n",
    "        data.append(storeRating)\n",
    "        data.append(storeRatingCount.split()[2] if storeRatingCount else storeRatingCount) \n",
    "        data.append(fbn)\n",
    "        data.append(link)\n",
    "        \n",
    "        count=count+1\n",
    "        \n",
    "        ## append data in excel file\n",
    "        page.append(data)\n",
    "        wb.save(filename=workbook_name) ## saving data to excel file made initially\n",
    "        \n",
    "        ## Going back ward\n",
    "        time.sleep(1)\n",
    "        driver.back()\n",
    "        time.sleep(1)\n",
    "        driver.back()\n",
    "\n",
    "    current_page = current_page + 1\n",
    "    ## for next page url \n",
    "    page_url = \"https://www.noon.com/egypt-en/sports-and-outdoors/exercise-and-fitness/yoga-16328/?limit=50&page=\"+str(current_page)+\"&sort%5Bby%5D=popularity&sort%5Bdir%5D=desc\"\n",
    "    driver.get(page_url)    ## opening next page url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()  ## close chrome driver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
